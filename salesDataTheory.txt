K-Means Clustering Algorithm:
K-Means Clustering is an Unsupervised Learning algorithm, which groups the unlabeled dataset into different
clusters. Here K defines the number of pre-defined clusters that need to be created in the process, as if K=2,
there will be two clusters, and for K=3, there will be three clusters, and so on.
It is an iterative algorithm that divides the unlabeled dataset into k different clusters in such a way that each
dataset belongs only one group that has similar properties.
It allows us to cluster the data into different groups and a convenient way to discover the categories of groups
in the unlabeled dataset on its own without the need for any training.
It is a centroid-based algorithm, where each cluster is associated with a centroid. The main aim of this
algorithm is to minimize the sum of distances between the data point and their corresponding clusters.
The algorithm takes the unlabeled dataset as input, divides the dataset into k-number of clusters, and repeats
the process until it does not find the best clusters. The value of k should be predetermined in this algorithm.
The k-means clustering algorithm mainly performs two tasks:
o Determines the best value for K center points or centroids by an iterative process.

o Assigns each data point to its closest k-center. Those data points which are near to the particular k-
center, create a cluster.

How does the K-Means Algorithm Work?
The working of the K-Means algorithm is explained in the below steps:

Department of Computer Engineering, SITS, Narhe LP III Lab Manual
Step-1: Select the number K to decide the number of clusters.
Step-2: Select random K points or centroids. (It can be other from the input dataset).
Step-3: Assign each data point to their closest centroid, which will form the predefined K clusters.
Step-4: Calculate the variance and place a new centroid of each cluster.
Step-5: Repeat the third step, which means reassign each datapoint to the new closest centroid of each cluster.
Step-6: If any reassignment occurs, then go to step-4 else go to FINISH.
Step-7: The model is ready.
Elbow Method:
The Elbow method is one of the most popular ways to find the optimal number of clusters. This method uses
the concept of WCSS value. WCSS stands for Within Cluster Sum of Squares, which defines the total
variations within a cluster. The formula to calculate the value of WCSS (for 3 clusters) is given below:
WCSS= ∑Pi in Cluster1 distance(Pi C1)^2+∑Pi in Cluster2distance(Pi C2)^2+∑Pi in CLuster3 distance(Pi C3)^2


**********code:**********

Libraries and Data Loading:
Import of necessary libraries: Pandas, NumPy, Seaborn, Matplotlib, and specific classes/modules from scikit-learn.
Reads the dataset into a Pandas DataFrame named df.
Displays the first few rows of the DataFrame using df.head().
Investigates the shape, summary statistics, information, missing values, and data types using methods like df.shape, df.describe(), df.info(), df.isnull().sum(), and df.dtypes.

Data Preprocessing:
Removes various categorical and null-containing columns that are deemed unnecessary for the analysis.
Converts categorical columns ('PRODUCTLINE' and 'DEALSIZE') into one-hot encoded dummy variables.
Converts the 'PRODUCTCODE' column to categorical codes.
Drops the 'ORDERDATE' column as 'Month' is already included.
Verifies that all data types are converted into numeric.

Elbow Method and KMeans Clustering:
Determines the optimal number of clusters by using the Elbow Method. Plots the distortion against a range of different cluster numbers.
Constructs the KMeans model with the chosen number of clusters (in this case, 3) and fits it to the data.
Predicts the clusters for each data point and counts the number of samples in each cluster.
Utilizes Principal Component Analysis (PCA) to reduce the dimensions of the dataset to two components for visualization.

Data Visualization:
Displays a scatter plot of the data points in the reduced two-dimensional space.
Identifies and plots the cluster centroids obtained from the KMeans model in the reduced space.
Separately visualizes the clusters using different colors for each cluster.